{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plmj/.local/share/virtualenvs/Serasa-7c30uEFG/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys, random\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "sys.path.insert(0, './sample')\n",
    "from sample.create_sample import create_sample\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining sample test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6ng6w.png', 'pxdwp.png', '74eyg.png', '8d8ep.png', 'e84n2.png', '2p2y8.png', 'b685n.png', '85pew.jpg', '8np22.png', '3den6.png']\n"
     ]
    }
   ],
   "source": [
    "sample_path = \"./data/samples\"\n",
    "random_sample = create_sample(size=10)\n",
    "print (random_sample)\n",
    "\n",
    "# for file_name in os.listdir(sample_path):\n",
    "#     print(file_name[:-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing some Images pre-processing\n",
    "1. Converting to greysacale; Simplifica a imagem, reduzindo a dimensionalidade e facilitando a segmentação.\n",
    "2. Binarização: Converte a imagem em uma imagem binária (preto e branco), facilitando a identificação de regiões de interesse. 0.5 devido ao fundo degradê ser bem definido.\n",
    "3. Remoção de Ruído\n",
    "\n",
    "4. Filtragem: \n",
    "4. 1. Média: Suaviza a imagem, reduzindo ruído gaussiano.\n",
    "4. 2. Mediana: Preserva bordas, eficaz contra ruído impulsivo (sal e pimenta).\n",
    "4. 3. Gaussiano: Suaviza a imagem, com maior preservação de detalhes.\n",
    "\n",
    "Morfologia Matemática:\n",
    "Dilatação: Engrossa linhas e objetos.\n",
    "Erosão: Afina linhas e objetos.\n",
    "Abertura: Remove pequenos objetos e preenche pequenos buracos.\n",
    "Fechamento: Preenche pequenos buracos e remove pequenos objetos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "def binarization(img):\n",
    "\tthreshold = 0.5\n",
    "\timg_binary = tf.where(img > threshold, 1.0, 0.0)\n",
    "\treturn img_binary\n",
    "\n",
    "def gaussian_transformation(img, kernel_size, sigma):\n",
    "\tx = tf.range(-kernel_size // 2 + 1, kernel_size // 2 + 1, dtype=tf.float32)\n",
    "\ty = x[:, tf.newaxis]\n",
    "\tkernel = tf.exp(-(x * x + y * y) / (2.0 * sigma * sigma))\n",
    "\tkernel = kernel / tf.reduce_sum(kernel)\n",
    "\n",
    "\t# Aplicar a convolução (filtragem Gaussiana)\n",
    "\timg_filtered = tf.nn.conv2d(img[tf.newaxis, :, :, :], kernel[tf.newaxis, :, :, tf.newaxis], strides=1, padding='SAME')\n",
    "\timg_filtered = tf.squeeze(img_filtered)\n",
    "\treturn img_filtered\n",
    "\n",
    "def median_transformation(img,median_kernel_size):\n",
    "\t# Extrai patches da imagem\n",
    "\tpatches = tf.image.extract_patches(\n",
    "\t\timages=img[tf.newaxis, :, :, tf.newaxis],\n",
    "\t\tsizes=[1, median_kernel_size, median_kernel_size, 1],\n",
    "\t\tstrides=[1, 1, 1, 1],\n",
    "\t\trates=[1, 1, 1, 1],\n",
    "\t\tpadding='SAME')\n",
    "\tpatches = tf.reshape(patches, [-1, median_kernel_size * median_kernel_size])\n",
    "\t # Ordena os valores em cada patch\n",
    "\tpatches_sorted = tf.sort(patches, axis=1)\n",
    "\n",
    "\t# Seleciona o valor mediano\n",
    "\tmedian_values = patches_sorted[:, median_kernel_size * median_kernel_size // 2]\n",
    "\n",
    "\t# Reconstrói a imagem\n",
    "\toutput = tf.reshape(median_values, tf.shape(img))\n",
    "\treturn output\n",
    "\n",
    "def erosion(image, element):\n",
    "    eroded = tf.nn.conv2d(image[tf.newaxis, :, :, tf.newaxis],\n",
    "                        element[tf.newaxis, :, :, tf.newaxis],\n",
    "                        strides=1, padding='SAME')\n",
    "    return tf.squeeze(eroded)\n",
    "\n",
    "def dilation(image, element):\n",
    "    dilated = tf.nn.max_pool(\n",
    "        tf.concat([image[tf.newaxis, :, :, tf.newaxis],\n",
    "                  -tf.ones_like(image[tf.newaxis, :, :, tf.newaxis])], axis=3),\n",
    "        ksize=[1, element.shape[0], element.shape[1], 1],\n",
    "        strides=1, padding='SAME')\n",
    "    return tf.squeeze(dilated)\n",
    "\n",
    "def image_processing(image_path, channels, gaussian_kernel, sigma, median_kernel):\n",
    "\telement = tf.ones((1, 1), dtype=tf.float32)\n",
    "\n",
    "\timg = tf.io.read_file(image_path)\n",
    "\timg = tf.image.decode_png(img, channels=channels)\n",
    "\t### Binarização\n",
    "\t# Converter para float32 e normalizar para o intervalo [0, 1]\n",
    "\timg = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "\t# Binarização (ajustar o limiar conforme necessário)\n",
    "\timg = binarization(img)\n",
    "\n",
    "\t# Criar um kernel Gaussiano\n",
    "\timg = gaussian_transformation(img, gaussian_kernel, sigma)\n",
    "\n",
    "\timg = median_transformation(img, median_kernel)\n",
    "\n",
    "\timg = dilation(img,element)\n",
    "\n",
    "\t# Visualizar a imagem binária\n",
    "\tplt.imshow(img, cmap='gray')\n",
    "\tplt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def cv_image_processing(image_path, gaussian_kernel, sigma, median_kernel, closing_k, dilation_k, method):\n",
    "\tkernel_d = np.ones(dilation_k, np.uint8)\n",
    "\tkernel_c = np.ones(closing_k, np.uint8)\n",
    "\n",
    "\timg = cv2.imread(image_path, 0)\n",
    "\t(h, w) = img.shape[:2]\n",
    "\timg = cv2.resize(img, (int(w*1.8), int(h*1.8)))\n",
    "\tret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\tif median_kernel != None:\n",
    "\t\tthresh = cv2.medianBlur(thresh, median_kernel)\n",
    "\n",
    "\tif gaussian_kernel != None:\n",
    "\t\tthresh = cv2.GaussianBlur(thresh, (gaussian_kernel, gaussian_kernel), sigma)\n",
    "\n",
    "\ttmp_path = \"./data/tmp/\" + image_path[-9:]\n",
    "\tif method == 'dilation' and dilation_k != None:\n",
    "\t\tdilation = cv2.dilate(thresh, kernel_d, iterations=1)\n",
    "\t\tdilation_image = Image.fromarray(dilation, mode=\"L\")\n",
    "\t\tdilation_image.save(tmp_path,format='PNG')\n",
    "\t\t# dilation_buffer = io.BytesIO()\n",
    "\t\t# dilation_image.save(dilation_buffer,format='PNG')\n",
    "\t\treturn dilation_image\n",
    "\telif method == 'closing' and closing_k != None:\n",
    "\t\tclosing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_c)\n",
    "\t\tclosing_image = Image.fromarray(closing, mode=\"L\")\n",
    "\t\tclosing_image.save(tmp_path,format='PNG')\n",
    "\t\t# closing_buffer = io.BytesIO()\n",
    "\t\t# closing_image.save(closing_buffer,format='PNG')\n",
    "\t\treturn closing_image\n",
    "\telse:\n",
    "\t\treturn Image.fromarray(thresh, mode=\"L\")\n",
    "\n",
    "\t# cv2.imshow('Original', img)\n",
    "\t# # cv2.imshow('Blur', blur)\n",
    "\t# cv2.imshow('Median', median)\n",
    "\t# cv2.imshow('Dilation', dilation)\n",
    "\t# cv2.imshow('Closing', closing)\n",
    "\n",
    "\t# cv2.waitKey(0)\n",
    "\t# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload to GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_gemini(path, mime_type=None):\n",
    "  file = genai.upload_file(path, mime_type=mime_type)\n",
    "  return file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def captcha_decoder(captcha):\n",
    "    # Create the model\n",
    "    generation_config = {\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0.95,\n",
    "        \"top_k\": 40,\n",
    "        \"max_output_tokens\": 256,\n",
    "        \"response_mime_type\": \"text/plain\",\n",
    "    }\n",
    "\n",
    "    files = [\n",
    "        upload_to_gemini(captcha,mime_type=\"image/png\"),\n",
    "    ]\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "    chat_session = model.start_chat(\n",
    "        history=[{\n",
    "                \"role\": \"user\",\n",
    "                \"parts\": [\n",
    "                    files[0],\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    response = chat_session.send_message(\"Act as a 5 characters captcha breaker and tell me whats the captcha on the image? Response only with the text in lowercase. If you cannnot detect any text, tell me only: 'NONE'. Remember all captha has 5 characters that can be alphanumeric\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytessract Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "def pytesseract_captcha(captcha):\n",
    "\tprint(captcha)\n",
    "\timg = Image.open(captcha)\n",
    "\tresponse = pytesseract.image_to_string(img)\n",
    "\t# print(response)\n",
    "\treturn response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decaptcha with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "captcha_response = []\n",
    "# dilation or closing\n",
    "method = 'closing'\n",
    "for sample in random_sample:\n",
    "\timage_path = sample_path + \"/\" + sample\n",
    "\ttmp_path = \"./data/tmp/\" + sample\n",
    "\timages = cv_image_processing(image_path,\n",
    "\t\t\t\t\t gaussian_kernel=None, sigma=0.5,\n",
    "\t\t\t\t\t median_kernel=None,\n",
    "\t\t\t\t\t closing_k=(5,5),\n",
    "\t\t\t\t\t dilation_k=(3,5),\n",
    "\t\t\t\t\t method = method)\n",
    "\tresponse = captcha_decoder(tmp_path)\n",
    "\tcaptcha_response.append(re.sub(r\"[\\n\\t\\s]*\", \"\", response))\n",
    "\t# os.remove(tmp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decaptcha With pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "tesseract_response = []\n",
    "# dilation or closing\n",
    "method = 'dilation'\n",
    "for sample in random_sample:\n",
    "\timage_path = sample_path + \"/\" + sample\n",
    "\ttmp_path = \"./data/tmp/\" + sample\n",
    "\timages = cv_image_processing(image_path,\n",
    "\t\t\t\t\t gaussian_kernel=None, sigma=0.5,\n",
    "\t\t\t\t\t median_kernel=1,\n",
    "\t\t\t\t\t closing_k=(1,1),\n",
    "\t\t\t\t\t dilation_k=(3,3),\n",
    "\t\t\t\t\t method=method)\n",
    "\tresponse = pytesseract.image_to_string(images, config='--psm 10')\n",
    "\ttesseract_response.append(re.sub(r\"[\\n\\t\\s]*\", \"\", response))\n",
    "\t# os.remove(tmp_path)\n",
    "\n",
    "# print(random_sample[:-4], response.text)\n",
    "# print(\"OK\") if response.text == random_sample[:-3] else print(\"no\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample.test_sample import test_sample\n",
    "metrics = test_sample(random_sample, tesseract_response)\n",
    "# metrics_llm = test_sample(random_sample, captcha_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'tested': 'GreGw', 'ground': '6ng6w', 'recall': 0},\n",
       "  {'tested': 'wxdwip—', 'ground': 'pxdwp', 'recall': 0},\n",
       "  {'tested': 'deyq', 'ground': '74eyg', 'recall': 0},\n",
       "  {'tested': '(BAseD_', 'ground': '8d8ep', 'recall': 0},\n",
       "  {'tested': 'a', 'ground': 'e84n2', 'recall': 0},\n",
       "  {'tested': 'a', 'ground': '2p2y8', 'recall': 0},\n",
       "  {'tested': 'H685a', 'ground': 'b685n', 'recall': 0},\n",
       "  {'tested': 'S5paw', 'ground': '85pew', 'recall': 0},\n",
       "  {'tested': 'Byp22', 'ground': '8np22', 'recall': 0},\n",
       "  {'tested': '3den6—', 'ground': '3den6', 'recall': 0}],\n",
       " 'metrics': 0.0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for file_name in os.listdir('./data/tmp'):\n",
    "    os.remove('./data/tmp/' + file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Serasa-7c30uEFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
