{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 12:28:23.839228: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-17 12:28:23.937871: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-17 12:28:24.081423: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731857304.201808   18180 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731857304.242082   18180 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-17 12:28:24.517100: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Bidirectional, LSTM, Dense, Input, Reshape\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crnn_with_attention(input_shape, num_classes):\n",
    "    timesteps = 5\n",
    "    # Input\n",
    "    inputs = Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    # Convolutional Layers\n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Flatten and Reshape for RNN Input\n",
    "    x = Reshape((timesteps, -1))(x)\n",
    "\n",
    "    # Bidirectional LSTM\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "    # Attention Mechanism\n",
    "    attention_output = Attention()([x, x])\n",
    "\n",
    "    # Fully Connected Layer for Classification\n",
    "    x = Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(attention_output)\n",
    "\n",
    "    outputs = Reshape((timesteps, num_classes))(x)\n",
    "    # Model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data for training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def cv_image_processing(image_path, gaussian_kernel, sigma, median_kernel, closing_k, dilation_k, method):\n",
    "\tkernel_d = np.ones(dilation_k, np.uint8)\n",
    "\tkernel_c = np.ones(closing_k, np.uint8)\n",
    "\n",
    "\timg = cv2.imread(image_path, 0)\n",
    "\t(h, w) = img.shape[:2]\n",
    "\timg = cv2.resize(img, (int(w*1.8), int(h*1.8)))\n",
    "\tret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\tif median_kernel != None:\n",
    "\t\tthresh = cv2.medianBlur(thresh, median_kernel)\n",
    "\n",
    "\tif gaussian_kernel != None:\n",
    "\t\tthresh = cv2.GaussianBlur(thresh, (gaussian_kernel, gaussian_kernel), sigma)\n",
    "\n",
    "\ttmp_path = \"./data/tmp/\" + image_path[-9:]\n",
    "\tif method == 'dilation' and dilation_k != None:\n",
    "\t\tdilation = cv2.dilate(thresh, kernel_d, iterations=1)\n",
    "\t\tdilation_image = Image.fromarray(dilation, mode=\"L\")\n",
    "\t\t# dilation_image.save(tmp_path,format='PNG')\n",
    "\t\t# dilation_buffer = io.BytesIO()\n",
    "\t\t# dilation_image.save(dilation_buffer,format='PNG')\n",
    "\t\treturn dilation\n",
    "\telif method == 'closing' and closing_k != None:\n",
    "\t\tclosing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_c)\n",
    "\t\tclosing_image = Image.fromarray(closing, mode=\"L\")\n",
    "\t\t# closing_image.save(tmp_path,format='PNG')\n",
    "\t\t# closing_buffer = io.BytesIO()\n",
    "\t\t# closing_image.save(closing_buffer,format='PNG')\n",
    "\t\treturn closing\n",
    "\telse:\n",
    "\t\treturn thresh\n",
    "\n",
    "\t# cv2.imshow('Original', img)\n",
    "\t# # cv2.imshow('Blur', blur)\n",
    "\t# cv2.imshow('Median', median)\n",
    "\t# cv2.imshow('Dilation', dilation)\n",
    "\t# cv2.imshow('Closing', closing)\n",
    "\n",
    "\t# cv2.waitKey(0)\n",
    "\t# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(data_dir, img_shape=(50, 200)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    # dilation or close\n",
    "    method = \"closing\"\n",
    "\n",
    "    # Listar todos os arquivos na pasta\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "            # Caminho completo para a imagem\n",
    "            img_path = os.path.join(data_dir, file_name)\n",
    "            img = cv_image_processing(img_path,\n",
    "                    gaussian_kernel=None, sigma=0.5,\n",
    "                    median_kernel=None,\n",
    "                    closing_k=(5,5),\n",
    "                    dilation_k=(3,5),\n",
    "                    method = method)\n",
    "            # Carregar a imagem e redimensionar\n",
    "            img = cv2.resize(img, img_shape)\n",
    "            images.append(img)\n",
    "\n",
    "            # Obter o rótulo (nome do arquivo sem a extensão)\n",
    "            label = os.path.splitext(file_name)[0]\n",
    "            labels.append(label)\n",
    "\n",
    "    # Converter listas para arrays numpy\n",
    "    images = np.array(images, dtype=np.float32) / 255.0  # Normalizar pixels (0 a 1)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating One-hot encoding for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, max_length=5):\n",
    "    # Flatten os caracteres (separar cada caractere)\n",
    "    chars = [char for label in labels for char in label]\n",
    "    chars = np.array(chars).reshape(-1, 1)\n",
    "    print(chars)\n",
    "    # Criar o OneHotEncoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    encoder.fit(chars)\n",
    "\n",
    "    # Codificar cada rótulo\n",
    "    encoded_labels = []\n",
    "    for label in labels:\n",
    "        # Codificar cada caractere e concatenar\n",
    "        encoded = np.vstack([encoder.transform([[char]]) for char in label])\n",
    "        encoded_labels.append(encoded)\n",
    "\n",
    "    # Padronizar para comprimento fixo (max_length)\n",
    "    encoded_labels = np.array(encoded_labels).reshape(-1, 5, 19)\n",
    "    return encoded_labels, encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Leave one out with k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_leave_one_out(images, labels, splits):\n",
    "    loo = LeaveOneOut()\n",
    "    folds =  KFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "    # for train_index, test_index in loo.split(images):\n",
    "    #     train_images, test_images = images[train_index], images[test_index]\n",
    "    #     train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "    #     folds.append((train_images, train_labels, test_images, test_labels))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório com os Captchas\n",
    "data_dir = '../data/samples'\n",
    "\n",
    "# 1. Carregar imagens e rótulos\n",
    "images, labels = load_images_and_labels(data_dir, img_shape=(50, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8']\n",
      " ['e']\n",
      " ['g']\n",
      " ...\n",
      " ['3']\n",
      " ['d']\n",
      " ['w']]\n",
      "[['f']\n",
      " ['x']\n",
      " ['p']\n",
      " ...\n",
      " ['e']\n",
      " ['x']\n",
      " ['3']]\n",
      "Epoch 1/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 897ms/step - accuracy: 0.0570 - loss: 3.0456 - val_accuracy: 0.0953 - val_loss: 2.9263\n",
      "Epoch 2/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 728ms/step - accuracy: 0.1043 - loss: 2.9187 - val_accuracy: 0.0981 - val_loss: 2.8768\n",
      "Epoch 3/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 928ms/step - accuracy: 0.1269 - loss: 2.8288 - val_accuracy: 0.1355 - val_loss: 2.7455\n",
      "Epoch 4/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 814ms/step - accuracy: 0.1986 - loss: 2.5850 - val_accuracy: 0.1766 - val_loss: 2.5377\n",
      "Epoch 5/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 750ms/step - accuracy: 0.2837 - loss: 2.2785 - val_accuracy: 0.2439 - val_loss: 2.3657\n",
      "Epoch 6/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 762ms/step - accuracy: 0.3783 - loss: 1.9531 - val_accuracy: 0.2617 - val_loss: 2.2417\n",
      "Epoch 7/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 770ms/step - accuracy: 0.4396 - loss: 1.6868 - val_accuracy: 0.3112 - val_loss: 2.1155\n",
      "Epoch 8/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 828ms/step - accuracy: 0.5156 - loss: 1.4233 - val_accuracy: 0.3505 - val_loss: 2.0340\n",
      "Epoch 9/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 800ms/step - accuracy: 0.5803 - loss: 1.1624 - val_accuracy: 0.3421 - val_loss: 1.9813\n",
      "Epoch 10/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 812ms/step - accuracy: 0.6467 - loss: 0.9504 - val_accuracy: 0.3879 - val_loss: 1.8709\n",
      "Epoch 11/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 754ms/step - accuracy: 0.7119 - loss: 0.7592 - val_accuracy: 0.4178 - val_loss: 1.8111\n",
      "Epoch 12/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 804ms/step - accuracy: 0.7627 - loss: 0.6304 - val_accuracy: 0.4215 - val_loss: 1.8399\n",
      "Epoch 13/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 667ms/step - accuracy: 0.8017 - loss: 0.5420 - val_accuracy: 0.4542 - val_loss: 1.7705\n",
      "Epoch 14/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 798ms/step - accuracy: 0.8398 - loss: 0.4611 - val_accuracy: 0.4607 - val_loss: 1.7607\n",
      "Epoch 15/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 758ms/step - accuracy: 0.8599 - loss: 0.3930 - val_accuracy: 0.4561 - val_loss: 1.7172\n",
      "Epoch 16/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 798ms/step - accuracy: 0.8697 - loss: 0.3469 - val_accuracy: 0.4822 - val_loss: 1.6513\n",
      "Epoch 17/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 873ms/step - accuracy: 0.8942 - loss: 0.3002 - val_accuracy: 0.5056 - val_loss: 1.6521\n",
      "Epoch 18/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 822ms/step - accuracy: 0.9067 - loss: 0.2660 - val_accuracy: 0.5047 - val_loss: 1.6539\n",
      "Epoch 19/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 812ms/step - accuracy: 0.9216 - loss: 0.2244 - val_accuracy: 0.5243 - val_loss: 1.6335\n",
      "Epoch 20/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 708ms/step - accuracy: 0.9382 - loss: 0.1860 - val_accuracy: 0.5243 - val_loss: 1.6097\n",
      "Epoch 21/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 923ms/step - accuracy: 0.9471 - loss: 0.1645 - val_accuracy: 0.5299 - val_loss: 1.6140\n",
      "Epoch 22/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 792ms/step - accuracy: 0.9587 - loss: 0.1361 - val_accuracy: 0.5187 - val_loss: 1.6021\n",
      "Epoch 23/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 796ms/step - accuracy: 0.9660 - loss: 0.1198 - val_accuracy: 0.5542 - val_loss: 1.5421\n",
      "Epoch 24/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.9752 - loss: 0.0913 - val_accuracy: 0.5551 - val_loss: 1.5545\n",
      "Epoch 25/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 667ms/step - accuracy: 0.9808 - loss: 0.0773 - val_accuracy: 0.5607 - val_loss: 1.5486\n",
      "Epoch 26/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 779ms/step - accuracy: 0.9780 - loss: 0.0736 - val_accuracy: 0.5626 - val_loss: 1.5284\n",
      "Epoch 27/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 676ms/step - accuracy: 0.9843 - loss: 0.0535 - val_accuracy: 0.5738 - val_loss: 1.5172\n",
      "Epoch 28/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 763ms/step - accuracy: 0.9850 - loss: 0.0514 - val_accuracy: 0.5748 - val_loss: 1.5097\n",
      "Epoch 29/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 674ms/step - accuracy: 0.9848 - loss: 0.0432 - val_accuracy: 0.5738 - val_loss: 1.5121\n",
      "Epoch 30/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 710ms/step - accuracy: 0.9873 - loss: 0.0382 - val_accuracy: 0.5766 - val_loss: 1.5290\n",
      "Epoch 31/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 734ms/step - accuracy: 0.9878 - loss: 0.0362 - val_accuracy: 0.5813 - val_loss: 1.4980\n",
      "Epoch 32/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 662ms/step - accuracy: 0.9901 - loss: 0.0289 - val_accuracy: 0.5794 - val_loss: 1.5184\n",
      "Epoch 33/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 717ms/step - accuracy: 0.9909 - loss: 0.0261 - val_accuracy: 0.5776 - val_loss: 1.5134\n",
      "Epoch 34/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 673ms/step - accuracy: 0.9904 - loss: 0.0258 - val_accuracy: 0.5832 - val_loss: 1.5247\n",
      "Epoch 35/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 734ms/step - accuracy: 0.9892 - loss: 0.0257 - val_accuracy: 0.5879 - val_loss: 1.5096\n",
      "Epoch 36/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 779ms/step - accuracy: 0.9876 - loss: 0.0275 - val_accuracy: 0.5879 - val_loss: 1.5050\n",
      "Epoch 37/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 660ms/step - accuracy: 0.9930 - loss: 0.0194 - val_accuracy: 0.5879 - val_loss: 1.5231\n",
      "Epoch 38/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 770ms/step - accuracy: 0.9928 - loss: 0.0188 - val_accuracy: 0.5794 - val_loss: 1.5132\n",
      "Epoch 39/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 804ms/step - accuracy: 0.9905 - loss: 0.0235 - val_accuracy: 0.5841 - val_loss: 1.5058\n",
      "Epoch 40/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 772ms/step - accuracy: 0.9931 - loss: 0.0175 - val_accuracy: 0.5860 - val_loss: 1.5139\n",
      "Epoch 41/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 714ms/step - accuracy: 0.9946 - loss: 0.0149 - val_accuracy: 0.5850 - val_loss: 1.5198\n",
      "Epoch 42/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 687ms/step - accuracy: 0.9947 - loss: 0.0137 - val_accuracy: 0.5822 - val_loss: 1.5007\n",
      "Epoch 43/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 737ms/step - accuracy: 0.9924 - loss: 0.0168 - val_accuracy: 0.5813 - val_loss: 1.5153\n",
      "Epoch 44/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 683ms/step - accuracy: 0.9931 - loss: 0.0149 - val_accuracy: 0.5785 - val_loss: 1.5001\n",
      "Epoch 45/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 735ms/step - accuracy: 0.9950 - loss: 0.0121 - val_accuracy: 0.5850 - val_loss: 1.5168\n",
      "Epoch 46/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 742ms/step - accuracy: 0.9957 - loss: 0.0108 - val_accuracy: 0.5850 - val_loss: 1.5066\n",
      "Epoch 47/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 712ms/step - accuracy: 0.9953 - loss: 0.0112 - val_accuracy: 0.5832 - val_loss: 1.5164\n",
      "Epoch 48/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 714ms/step - accuracy: 0.9941 - loss: 0.0130 - val_accuracy: 0.5785 - val_loss: 1.5118\n",
      "Epoch 49/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 717ms/step - accuracy: 0.9935 - loss: 0.0134 - val_accuracy: 0.5907 - val_loss: 1.5213\n",
      "Epoch 50/50\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 700ms/step - accuracy: 0.9953 - loss: 0.0104 - val_accuracy: 0.5888 - val_loss: 1.5150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_labels, train_encoder = encode_labels(train_labels)\n",
    "test_labels, test_encoder = encode_labels(test_labels)\n",
    "\n",
    "model = build_crnn_with_attention(input_shape=(200,50, 1), num_classes=19)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=32,\n",
    "    epochs=50,  # Ajuste conforme necessário\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia no conjunto de teste: 0.5888\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2']\n",
      " ['2']\n",
      " ['6']\n",
      " ...\n",
      " ['n']\n",
      " ['5']\n",
      " ['7']]\n"
     ]
    }
   ],
   "source": [
    "encoded_labels, encoder = encode_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Configurar Leave-One-Out Cross Validation\n",
    "n_splits = 5\n",
    "folds = split_leave_one_out(images, encoded_labels, splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Fold 1/5...\n",
      "(214, 200, 50)\n",
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 918ms/step - accuracy: 0.0771 - loss: 2.9666 - val_accuracy: 0.0953 - val_loss: 2.9261\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 787ms/step - accuracy: 0.0991 - loss: 2.9174 - val_accuracy: 0.1056 - val_loss: 2.8598\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 920ms/step - accuracy: 0.1421 - loss: 2.7909 - val_accuracy: 0.1710 - val_loss: 2.7136\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 864ms/step - accuracy: 0.2196 - loss: 2.4906 - val_accuracy: 0.1981 - val_loss: 2.5089\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 799ms/step - accuracy: 0.3132 - loss: 2.1234 - val_accuracy: 0.2748 - val_loss: 2.2455\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 795ms/step - accuracy: 0.4192 - loss: 1.7237 - val_accuracy: 0.2813 - val_loss: 2.2084\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 777ms/step - accuracy: 0.4759 - loss: 1.4643 - val_accuracy: 0.3280 - val_loss: 2.0772\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 830ms/step - accuracy: 0.5743 - loss: 1.1610 - val_accuracy: 0.3523 - val_loss: 2.0090\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 824ms/step - accuracy: 0.6492 - loss: 0.9544 - val_accuracy: 0.3879 - val_loss: 1.9495\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 771ms/step - accuracy: 0.7150 - loss: 0.7684 - val_accuracy: 0.4084 - val_loss: 1.8970\n",
      "Fold 1 - Loss: 1.8970, Accuracy: 0.4084\n",
      "Treinando Fold 2/5...\n",
      "(214, 200, 50)\n",
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 918ms/step - accuracy: 0.0717 - loss: 3.0392 - val_accuracy: 0.0897 - val_loss: 2.9346\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 758ms/step - accuracy: 0.1018 - loss: 2.9133 - val_accuracy: 0.0925 - val_loss: 2.8906\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 906ms/step - accuracy: 0.1198 - loss: 2.8170 - val_accuracy: 0.1262 - val_loss: 2.7701\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 745ms/step - accuracy: 0.2062 - loss: 2.5748 - val_accuracy: 0.1673 - val_loss: 2.6426\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 888ms/step - accuracy: 0.2792 - loss: 2.2563 - val_accuracy: 0.2037 - val_loss: 2.4974\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 799ms/step - accuracy: 0.3638 - loss: 1.9644 - val_accuracy: 0.2664 - val_loss: 2.3462\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 813ms/step - accuracy: 0.4394 - loss: 1.6529 - val_accuracy: 0.2850 - val_loss: 2.2682\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 775ms/step - accuracy: 0.5098 - loss: 1.3950 - val_accuracy: 0.2991 - val_loss: 2.1945\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 890ms/step - accuracy: 0.5440 - loss: 1.2076 - val_accuracy: 0.3271 - val_loss: 2.1475\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 826ms/step - accuracy: 0.6024 - loss: 0.9983 - val_accuracy: 0.3421 - val_loss: 2.0844\n",
      "Fold 2 - Loss: 2.0844, Accuracy: 0.3421\n",
      "Treinando Fold 3/5...\n",
      "(214, 200, 50)\n",
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 771ms/step - accuracy: 0.0785 - loss: 3.0374 - val_accuracy: 0.1037 - val_loss: 2.9233\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 834ms/step - accuracy: 0.0995 - loss: 2.9105 - val_accuracy: 0.1271 - val_loss: 2.8424\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 714ms/step - accuracy: 0.1569 - loss: 2.7635 - val_accuracy: 0.1748 - val_loss: 2.6264\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 804ms/step - accuracy: 0.2488 - loss: 2.4101 - val_accuracy: 0.2523 - val_loss: 2.3595\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 784ms/step - accuracy: 0.3336 - loss: 2.0432 - val_accuracy: 0.2953 - val_loss: 2.1816\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 886ms/step - accuracy: 0.4130 - loss: 1.7286 - val_accuracy: 0.3617 - val_loss: 2.0039\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 735ms/step - accuracy: 0.5069 - loss: 1.4112 - val_accuracy: 0.3850 - val_loss: 1.9481\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 741ms/step - accuracy: 0.5769 - loss: 1.1477 - val_accuracy: 0.4093 - val_loss: 1.8206\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 703ms/step - accuracy: 0.6676 - loss: 0.8995 - val_accuracy: 0.4467 - val_loss: 1.7575\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 725ms/step - accuracy: 0.7287 - loss: 0.7303 - val_accuracy: 0.4607 - val_loss: 1.6914\n",
      "Fold 3 - Loss: 1.6914, Accuracy: 0.4607\n",
      "Treinando Fold 4/5...\n",
      "(214, 200, 50)\n",
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 766ms/step - accuracy: 0.0654 - loss: 3.0122 - val_accuracy: 0.1112 - val_loss: 2.9189\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 716ms/step - accuracy: 0.1009 - loss: 2.9115 - val_accuracy: 0.1196 - val_loss: 2.8266\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 737ms/step - accuracy: 0.1351 - loss: 2.7452 - val_accuracy: 0.1953 - val_loss: 2.6627\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 748ms/step - accuracy: 0.2359 - loss: 2.4060 - val_accuracy: 0.2224 - val_loss: 2.4514\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 723ms/step - accuracy: 0.3291 - loss: 2.0720 - val_accuracy: 0.2850 - val_loss: 2.2733\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 747ms/step - accuracy: 0.4154 - loss: 1.7246 - val_accuracy: 0.3308 - val_loss: 2.1098\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 744ms/step - accuracy: 0.5037 - loss: 1.4225 - val_accuracy: 0.3505 - val_loss: 2.0094\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 730ms/step - accuracy: 0.5790 - loss: 1.1724 - val_accuracy: 0.3804 - val_loss: 1.9250\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 815ms/step - accuracy: 0.6504 - loss: 0.9414 - val_accuracy: 0.4047 - val_loss: 1.9092\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 740ms/step - accuracy: 0.6992 - loss: 0.7858 - val_accuracy: 0.4262 - val_loss: 1.8605\n",
      "Fold 4 - Loss: 1.8605, Accuracy: 0.4262\n",
      "Treinando Fold 5/5...\n",
      "(214, 200, 50)\n",
      "Epoch 1/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 750ms/step - accuracy: 0.0734 - loss: 3.0351 - val_accuracy: 0.1047 - val_loss: 2.9197\n",
      "Epoch 2/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 729ms/step - accuracy: 0.1031 - loss: 2.9156 - val_accuracy: 0.1047 - val_loss: 2.8855\n",
      "Epoch 3/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 785ms/step - accuracy: 0.1066 - loss: 2.8489 - val_accuracy: 0.1411 - val_loss: 2.7778\n",
      "Epoch 4/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 741ms/step - accuracy: 0.1698 - loss: 2.6329 - val_accuracy: 0.2065 - val_loss: 2.5790\n",
      "Epoch 5/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 748ms/step - accuracy: 0.2670 - loss: 2.3212 - val_accuracy: 0.2570 - val_loss: 2.3965\n",
      "Epoch 6/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 743ms/step - accuracy: 0.3352 - loss: 2.0281 - val_accuracy: 0.2897 - val_loss: 2.2713\n",
      "Epoch 7/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 703ms/step - accuracy: 0.4179 - loss: 1.7316 - val_accuracy: 0.3065 - val_loss: 2.2170\n",
      "Epoch 8/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 805ms/step - accuracy: 0.4845 - loss: 1.4456 - val_accuracy: 0.3299 - val_loss: 2.1318\n",
      "Epoch 9/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 733ms/step - accuracy: 0.5658 - loss: 1.1923 - val_accuracy: 0.3607 - val_loss: 2.0815\n",
      "Epoch 10/10\n",
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 681ms/step - accuracy: 0.6395 - loss: 0.9766 - val_accuracy: 0.3897 - val_loss: 2.0155\n",
      "Fold 5 - Loss: 2.0155, Accuracy: 0.3897\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_fold = []\n",
    "# Iterar sobre os folds\n",
    "for fold, (train_idx, test_idx) in enumerate(folds.split(images)):\n",
    "    print(f\"Treinando Fold {fold + 1}/{n_splits}...\")\n",
    "\n",
    "    # Separar os dados do fold atual\n",
    "    train_images, test_images = images[train_idx], images[test_idx]\n",
    "    train_labels, test_labels = encoded_labels[train_idx], encoded_labels[test_idx]\n",
    "    print(test_images.shape)\n",
    "    # Criar um novo modelo para cada fold (para evitar reutilizar pesos)\n",
    "    model = build_crnn_with_attention(input_shape=(200,50, 1), num_classes=19)\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    # model.summary()\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(test_images, test_labels),\n",
    "        batch_size=32,\n",
    "        epochs=10,  # Ajuste conforme necessário\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Avaliar no conjunto de teste\n",
    "    loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Armazenar a acurácia do fold\n",
    "    accuracy_per_fold.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados finais:\n",
      "Acurácia média: 0.4054\n",
      "Desvio padrão da acurácia: 0.0394\n"
     ]
    }
   ],
   "source": [
    "# Resultados médios\n",
    "print(\"\\nResultados finais:\")\n",
    "print(f\"Acurácia média: {np.mean(accuracy_per_fold):.4f}\")\n",
    "print(f\"Desvio padrão da acurácia: {np.std(accuracy_per_fold):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados \n",
    "## 5-fold 10 Epochs\n",
    "### Dilation preprocessing:\n",
    "- Acurácia média: 0.4105\n",
    "- Desvio padrão da acurácia: 0.0174\n",
    "### Closing preprocessing\n",
    "- Acurácia média: 0.4054\n",
    "- Desvio padrão da acurácia: 0.0394\n",
    "\n",
    "## 0.2 Stratification\n",
    "### 10 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0.3916\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.3308\n",
    "\n",
    "### 30 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.5355\n",
    "\n",
    "### 50 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0.\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.\n",
    "\n",
    "### 100 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0.\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Serasa-7c30uEFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
