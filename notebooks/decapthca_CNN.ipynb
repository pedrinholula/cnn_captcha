{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "This notebook was made for fast test new CNN models and parameters over the time.\n",
    "Every section will be explained theirself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D, MaxPooling2D, Flatten, Bidirectional, LSTM, Dense, Input, Reshape\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crnn_with_attention(input_shape, num_classes):\n",
    "    timesteps = 5\n",
    "    # Input\n",
    "    inputs = Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    # Convolutional Layers\n",
    "    x = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Flatten and Reshape for RNN Input\n",
    "    x = Reshape((timesteps, -1))(x)\n",
    "\n",
    "    # Bidirectional LSTM\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "    # Attention Mechanism\n",
    "    attention_output = Attention()([x, x])\n",
    "\n",
    "    # Fully Connected Layer for Classification\n",
    "    x = Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(attention_output)\n",
    "\n",
    "    outputs = Reshape((timesteps, num_classes))(x)\n",
    "    # Model\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Data for training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def cv_image_processing(image_path, gaussian_kernel, sigma, median_kernel, closing_k, dilation_k, method):\n",
    "\tkernel_d = np.ones(dilation_k, np.uint8)\n",
    "\tkernel_c = np.ones(closing_k, np.uint8)\n",
    "\n",
    "\timg = cv2.imread(image_path, 0)\n",
    "\t(h, w) = img.shape[:2]\n",
    "\timg = cv2.resize(img, (int(w*1.8), int(h*1.8)))\n",
    "\tret, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "\tif median_kernel != None:\n",
    "\t\tthresh = cv2.medianBlur(thresh, median_kernel)\n",
    "\n",
    "\tif gaussian_kernel != None:\n",
    "\t\tthresh = cv2.GaussianBlur(thresh, (gaussian_kernel, gaussian_kernel), sigma)\n",
    "\n",
    "\ttmp_path = \"./data/tmp/\" + image_path[-9:]\n",
    "\tif method == 'dilation' and dilation_k != None:\n",
    "\t\tdilation = cv2.dilate(thresh, kernel_d, iterations=1)\n",
    "\t\tdilation_image = Image.fromarray(dilation, mode=\"L\")\n",
    "\t\t# dilation_image.save(tmp_path,format='PNG')\n",
    "\t\t# dilation_buffer = io.BytesIO()\n",
    "\t\t# dilation_image.save(dilation_buffer,format='PNG')\n",
    "\t\treturn dilation\n",
    "\telif method == 'closing' and closing_k != None:\n",
    "\t\tclosing = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel_c)\n",
    "\t\tclosing_image = Image.fromarray(closing, mode=\"L\")\n",
    "\t\t# closing_image.save(tmp_path,format='PNG')\n",
    "\t\t# closing_buffer = io.BytesIO()\n",
    "\t\t# closing_image.save(closing_buffer,format='PNG')\n",
    "\t\treturn closing\n",
    "\telse:\n",
    "\t\treturn thresh\n",
    "\n",
    "\t# cv2.imshow('Original', img)\n",
    "\t# # cv2.imshow('Blur', blur)\n",
    "\t# cv2.imshow('Median', median)\n",
    "\t# cv2.imshow('Dilation', dilation)\n",
    "\t# cv2.imshow('Closing', closing)\n",
    "\n",
    "\t# cv2.waitKey(0)\n",
    "\t# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Images and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(data_dir, img_shape=(50, 200)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    # dilation or close\n",
    "    method = \"closing\"\n",
    "    x=0\n",
    "    # Listar todos os arquivos na pasta\n",
    "    for file_name in os.listdir(data_dir):\n",
    "        if file_name.endswith('.png') or file_name.endswith('.jpg'):\n",
    "            # Caminho completo para a imagem\n",
    "            img_path = os.path.join(data_dir, file_name)\n",
    "            img = cv_image_processing(img_path,\n",
    "                    gaussian_kernel=None, sigma=0.5,\n",
    "                    median_kernel=None,\n",
    "                    closing_k=(5,5),\n",
    "                    dilation_k=(3,5),\n",
    "                    method = method)\n",
    "            # Carregar a imagem e redimensionar\n",
    "            img = cv2.resize(img, img_shape)\n",
    "            images.append(img)\n",
    "\n",
    "            # Obter o rótulo (nome do arquivo sem a extensão)\n",
    "            label = os.path.splitext(file_name)[0]\n",
    "            labels.append(label)\n",
    "\n",
    "    # Converter listas para arrays numpy\n",
    "    images = np.array(images, dtype=np.float32) / 255.0  # Normalizar pixels (0 a 1)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating One-hot encoding for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels, max_length=5):\n",
    "    # Flatten os caracteres (separar cada caractere)\n",
    "    chars = [char for label in labels for char in label]\n",
    "    chars = np.array(chars).reshape(-1, 1)\n",
    "    print(chars)\n",
    "    # Criar o OneHotEncoder\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    encoder.fit(chars)\n",
    "\n",
    "    # Codificar cada rótulo\n",
    "    encoded_labels = []\n",
    "    for label in labels:\n",
    "        # Codificar cada caractere e concatenar\n",
    "        encoded = np.vstack([encoder.transform([[char]]) for char in label])\n",
    "        encoded_labels.append(encoded)\n",
    "\n",
    "    # Padronizar para comprimento fixo (max_length)\n",
    "    encoded_labels = np.array(encoded_labels).reshape(-1, 5, 19)\n",
    "    return encoded_labels, encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Leave one out with k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_leave_one_out(images, labels, splits):\n",
    "    loo = LeaveOneOut()\n",
    "    folds =  KFold(n_splits=splits, shuffle=True, random_state=42)\n",
    "    # for train_index, test_index in loo.split(images):\n",
    "    #     train_images, test_images = images[train_index], images[test_index]\n",
    "    #     train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "    #     folds.append((train_images, train_labels, test_images, test_labels))\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório com os Captchas\n",
    "data_dir = '../data/samples'\n",
    "\n",
    "# 1. Carregar imagens e rótulos\n",
    "images, labels = load_images_and_labels(data_dir, img_shape=(200, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "train_labels, train_encoder = encode_labels(train_labels)\n",
    "test_labels, test_encoder = encode_labels(test_labels)\n",
    "\n",
    "model = build_crnn_with_attention(input_shape=(200,50, 1), num_classes=19)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "# model.summary()\n",
    "\n",
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=32,\n",
    "    epochs=5,  # Ajuste conforme necessário\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f\"Acurácia no conjunto de teste: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels, encoder = encode_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. Configurar Leave-One-Out Cross Validation\n",
    "n_splits = 5\n",
    "folds = split_leave_one_out(images, encoded_labels, splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_per_fold = []\n",
    "# Iterar sobre os folds\n",
    "for fold, (train_idx, test_idx) in enumerate(folds.split(images)):\n",
    "    print(f\"Treinando Fold {fold + 1}/{n_splits}...\")\n",
    "\n",
    "    # Separar os dados do fold atual\n",
    "    train_images, test_images = images[train_idx], images[test_idx]\n",
    "    train_labels, test_labels = encoded_labels[train_idx], encoded_labels[test_idx]\n",
    "    print(test_images.shape)\n",
    "    # Criar um novo modelo para cada fold (para evitar reutilizar pesos)\n",
    "    model = build_crnn_with_attention(input_shape=(200,50, 1), num_classes=19)\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    # model.summary()\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = model.fit(\n",
    "        train_images, train_labels,\n",
    "        validation_data=(test_images, test_labels),\n",
    "        batch_size=32,\n",
    "        epochs=10,  # Ajuste conforme necessário\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Avaliar no conjunto de teste\n",
    "    loss, accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "    print(f\"Fold {fold + 1} - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Armazenar a acurácia do fold\n",
    "    accuracy_per_fold.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados médios\n",
    "print(\"\\nResultados finais:\")\n",
    "print(f\"Acurácia média: {np.mean(accuracy_per_fold):.4f}\")\n",
    "print(f\"Desvio padrão da acurácia: {np.std(accuracy_per_fold):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados \n",
    "## 5-fold 10 Epochs\n",
    "### Dilation preprocessing:\n",
    "- Acurácia média: 0.4105\n",
    "- Desvio padrão da acurácia: 0.0174\n",
    "### Closing preprocessing\n",
    "- Acurácia média: 0.4054\n",
    "- Desvio padrão da acurácia: 0.0394\n",
    "\n",
    "## 0.2 Stratification\n",
    "### 10 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0.3916\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.3308\n",
    "\n",
    "### 30 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0.5430\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.5355\n",
    "\n",
    "### 50 Epochs\n",
    "#### Closing\n",
    "- Acurácia média: 0.5551\n",
    "#### Dilation: \n",
    "- Acurácia média: 0.5888\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Serasa-7c30uEFG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
